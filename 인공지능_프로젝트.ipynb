{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "인공지능 프로젝트.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aBXZVi7C_Wf"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1vaB1n5pDYyr"
      },
      "source": [
        "import torch\r\n",
        "from torchvision import models, datasets, transforms\r\n",
        "import torch.optim as optim\r\n",
        "from torch import nn\r\n",
        "import os\r\n",
        "from PIL import Image\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJjpz6cQDZ6q"
      },
      "source": [
        "!nvidia-smi\r\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6zQXu8vDa3q"
      },
      "source": [
        "# 모델 불러오기 가장 유명한 resnet18을 이용하여 사용 (기존에 학습된것을 이용 기존 학습의 경우 1000개의 class를 구분 짓는 모델이여서 마지막 fully connected layer에서 1000을 현재 데이터에 맞는 3으로 변경)\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision\r\n",
        "#net = torchvision.models.vgg16(pretrained = True)\r\n",
        "#net.classifier[6] = nn.Linear(4096,3)\r\n",
        "net = torchvision.models.resnet18(pretrained = True)\r\n",
        "#net = torchvision.models.resnet34(pretrained = True)\r\n",
        "#net = torchvision.models.resnet50(pretrained = True)\r\n",
        "net.fc = nn.Linear(net.fc.in_features,3)\r\n",
        "net = net.to(0)\r\n",
        "\r\n",
        "# loss, optimizer 설계\r\n",
        "criterion = nn.CrossEntropyLoss()\r\n",
        "\r\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.0001)\r\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.0001)"
     
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5PuKLGRrHZo1"
      },
      "source": [
        "classes = ('Covid', 'Normal', 'Viral Pneumonia')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ptvv-hlDdBJ"
      },
      "source": [
        "##########################################\r\n",
        "\r\n",
        "for epoch in range(5):  # 얼마나 반복시키면서 학습할껀지\r\n",
        "    trainset = datasets.ImageFolder(root='/content/drive/MyDrive/Covid19-dataset/train/',transform = transforms.Compose([transforms.Grayscale(3),transforms.Resize((512,512)),transforms.RandomHorizontalFlip(),transforms.RandomVerticalFlip(),transforms.RandomRotation(5),transforms.ToTensor()]))\r\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,\r\n",
        "                                              shuffle=True,num_workers = 4)\r\n",
        "\r\n",
        "    testset = datasets.ImageFolder(root='/content/drive/MyDrive/Covid19-dataset/test/',transform = transforms.Compose([transforms.Grayscale(3),transforms.Resize((512,512)),transforms.ToTensor()]))\r\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=16,\r\n",
        "                                              shuffle=False,num_workers = 4)\r\n",
        "    running_loss = 0.0\r\n",
        "    temp,total = 0, 0\r\n",
        "    for i, data in enumerate(trainloader):\r\n",
        "        inputs, labels = data\r\n",
        "        inputs, labels = inputs.to(0), labels.to(0)\r\n",
        "        optimizer.zero_grad()\r\n",
        "\r\n",
        "        outputs = net(inputs)\r\n",
        "        loss = criterion(outputs, labels)\r\n",
        "        loss.backward()\r\n",
        "        optimizer.step()\r\n",
        "        _, predicted = torch.max(outputs.data, 1)\r\n",
        "        temp += (predicted == labels).sum().item()\r\n",
        "        total += inputs.shape[0]\r\n",
        "\r\n",
        "        # print statistics\r\n",
        "        running_loss += loss.item()\r\n",
        "        if i % 2 == 0:    # 매번 출력하면 힘드니까 2번당 1번씩 출력\r\n",
        "            print('[%d, %5d] trainloss: %.3f, trainaccuracy : %.2f' %\r\n",
        "                  (epoch + 1, i + 1, running_loss / 2, (temp/total)))\r\n",
        "            #print('train accuracy : %.2f' % (temp / total))\r\n",
        "            running_loss = 0.0\r\n",
        "            temp,total = 0, 0\r\n",
        "\r\n",
        "    for i, data in enumerate(testloader):\r\n",
        "        inputs, labels = data\r\n",
        "        inputs, labels = inputs.to(0), labels.to(0)\r\n",
        "        outputs = net(inputs)\r\n",
        "        loss = criterion(outputs, labels)\r\n",
        "        _, predicted = torch.max(outputs.data, 1)\r\n",
        "        temp += (predicted == labels).sum().item()\r\n",
        "        total += inputs.shape[0]\r\n",
        "\r\n",
        "        # print statistics\r\n",
        "        running_loss += loss.item()\r\n",
        "        if i % 2 == 0:    # 매번 출력하면 힘드니까 2번당 1번씩 출력\r\n",
        "            print('[%d, %5d] testloss: %.3f, testaccuracy : %.2f' %\r\n",
        "                  (epoch + 1, i + 1, running_loss / 2, (temp/total)))\r\n",
        "            running_loss = 0.0\r\n",
        "            temp,total = 0, 0\r\n",
        "print('Finished Training')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSG0tUe9Dg2i"
      },
      "source": [
        "correct = 0\r\n",
        "total = 0\r\n",
        "with torch.no_grad():\r\n",
        "    for data in testloader:\r\n",
        "        images, labels = data\r\n",
        "        images, labels = images.to(0), labels.to(0)\r\n",
        "        outputs = net(images)\r\n",
        "        _, predicted = torch.max(outputs.data, 1)\r\n",
        "        total += labels.size(0)\r\n",
        "        correct += (predicted == labels).sum().item()\r\n",
        "\r\n",
        "print('test셋 결과물: %d %%' % (\r\n",
        "    100 * correct / total))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2U8s8Gz-DiZh"
      },
      "source": [
        "############# 최종 평가\r\n",
        "mat = torch.zeros((3,3))\r\n",
        "class_correct = list(0. for i in range(3))\r\n",
        "class_total = list(0. for i in range(3))\r\n",
        "with torch.no_grad():\r\n",
        "    for data in testloader:\r\n",
        "        images, labels = data\r\n",
        "        images, labels = images.to(0), labels.to(0)\r\n",
        "        outputs = net(images)\r\n",
        "        _, predicted = torch.max(outputs.data, 1)\r\n",
        "        print(predicted, labels)\r\n",
        "        c = (predicted == labels).squeeze()\r\n",
        "        for i in range(2):\r\n",
        "            label = labels[i]\r\n",
        "            class_correct[label] += c[i].item()\r\n",
        "            class_total[label] += 1\r\n",
        "        for i,x in enumerate(labels):\r\n",
        "          mat[predicted[i],x] += 1\r\n",
        "print(mat)\r\n",
        "for i in range(3):\r\n",
        "    print('Accuracy of %5s : %2d %%' % (\r\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
